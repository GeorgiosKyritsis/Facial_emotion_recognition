Facial emotion recognition has been an active research topic for decades. Early approaches were based on manually designed or hand-crafted features such as SIFT~\cite{berretti2010set}, Gabor Wavelets~\cite{zhang1999feature}, Histograms of Oriented Gradients (HOGs)~\cite{deniz2011face}, Local Binary Patterns (LBP)~\cite{shan2009facial}, Local Binary Patterns on Three Orthogonal Planes (LBP-TOP)~\cite{zhao2007dynamic}, Local Phase Quantization (LPQ)~\cite{wang2012facial}, and Action Units~\cite{tian2001recognizing}. All these models lack generalization and their performance degrades significantly when they are applied to datasets that are different to the original dataset.

In recent years, convolutional neural networks (CNNs) have revolutionized computer vision. They were popularized by Yann LeCun's LeNet~\cite{lecun1990handwritten} at the 1990s but only recently it has been able to train these networks on large datasets due to the increased processing power afforded by graphical processing units (GPUs). We are now able to train very deep networks with millions of parameters on very large datasets like ImageNet~\cite{deng2009imagenet}. Image classification, which is major problem in computer vision, has been successfully tackled by deep convolutional neural networks~\cite{krizhevsky2012imagenet,szegedy2015going}. Since emotion recognition is an image classification task, CNN is also applied to this problem. In particular, Yu and Zhang achieved state-of-the-art results for the Emotion Recognition in the Wild challenge (EmotiW)~\cite{dhall2014emotion} in 2015 by using an ensemble of multiple deep convolutional neural networks with 5 convolutional layers each~\cite{yu2015image}. A novelty of this paper is the usage of stochastic pooling~\cite{zeiler2013stochastic} instead of max pooling. Also they used data perturbation and a voting method that increased the accuracy of the model by 2-3\%. Mollahoseini et al.~\cite{mollahosseini2016going} proposed an architecture consisting of 4 convolutional layers each followed by max pooling and then followed by 4 Inception layers as introduced by GoogLeNet~\cite{szegedy2015going}. The network was tested on many publicly available datasets, and achieved state-of-the-art accuracies on many of them. Barsoum et al. proposed a custom VGG13 model with 10 convolutional layers with max pooling and dropout layers in between that achieved state-of-the-art accuracy to the FER+ dataset~\cite{barsoum2016training}. 

%\afterpage{\blankpage}