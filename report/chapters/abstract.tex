Facial emotion recognition which is a challenging task has attracted research interest within the field of artificial intelligence. Many approaches are based on engineered features (e.g HOG, SIFT, Gabor Wavelets, and LPQ) where these features are given as input to classifiers. Nevertheless, the results generalise poorly to previously unseen data.

Recently, deep convolutional neural networks (CNN) have been trained to achieve state-of-the-art performance on a wide variety of tasks including, natural language processing, image classification, and speech recognition. This paper proposes a deep neural network architecture to address the FER problem which in conjunction with facial action units achieves state-of-the-art performance. Facial action unit is one of the most powerful and immediate means for humans to communicate their emotions.

The input images for our network are from the FER+ dataset which provides one emotion label for each face. Our network classifies each face based on the emotion shown in the facial expression in one of the eight categories (neutral, happy, surprise, sad, angry, disgust, fear, and contempt). 

\afterpage{\blankpage}